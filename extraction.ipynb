{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a04713-cb08-4f23-a0c3-d61c2c5687d9",
   "metadata": {},
   "source": [
    "## Installing some of the dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cc28e35b-d897-4d2f-aa7b-48e826ffbfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in ./myve/lib/python3.9/site-packages (2.9.10)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/apple/Desktop/tutorial/Postgresql_etl/myve/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: requests in ./myve/lib/python3.9/site-packages (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myve/lib/python3.9/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myve/lib/python3.9/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myve/lib/python3.9/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myve/lib/python3.9/site-packages (from requests) (3.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/apple/Desktop/tutorial/Postgresql_etl/myve/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: SQLAlchemy in ./myve/lib/python3.9/site-packages (2.0.36)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./myve/lib/python3.9/site-packages (from SQLAlchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./myve/lib/python3.9/site-packages (from SQLAlchemy) (3.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/apple/Desktop/tutorial/Postgresql_etl/myve/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install psycopg2 \n",
    "! pip install requests\n",
    "! pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053eb6f-ec79-46f8-9c39-8b9a8a0fad59",
   "metadata": {},
   "source": [
    "# Importing dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fde26f4c-9c8d-49d1-81e6-abf5bed33865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import requests\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49246b30-2c9c-4e79-ad48-8e5e0b4a1a33",
   "metadata": {},
   "source": [
    "# Extraction Layer: Extracting the dataset from RapidAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3065478c-f2ac-478f-b45c-4706746ed4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://realty-mole-property-api.p.rapidapi.com/randomProperties\"\n",
    "\n",
    "querystring = {\"limit\":\"2000\"}\n",
    "\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": \"ce3693686amshd8a81ba62ce435ep1113afjsn137d2b9aa172\",\n",
    "\t\"x-rapidapi-host\": \"realty-mole-property-api.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "# saving the data as a file\n",
    "\n",
    "filename = 'propertyRecords.json'\n",
    "\n",
    "# to write the file into the filename\n",
    "with open (filename, 'w') as file:\n",
    "    json.dump(data,file, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d2b6ed02-64fb-4df6-b603-673ae2f20a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read into a dataframe\n",
    "\n",
    "propertyrecords_df = pd.read_json('propertyRecords.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29eaa79-3cdd-45d7-b745-516574ffa015",
   "metadata": {},
   "source": [
    "# Transforming the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "71ad7a17-ad15-430b-9121-7ddb9de13b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 27 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   addressLine1      500 non-null    object \n",
      " 1   city              500 non-null    object \n",
      " 2   state             500 non-null    object \n",
      " 3   zipCode           500 non-null    int64  \n",
      " 4   formattedAddress  500 non-null    object \n",
      " 5   addressLine2      107 non-null    object \n",
      " 6   assessorID        372 non-null    object \n",
      " 7   county            499 non-null    object \n",
      " 8   legalDescription  359 non-null    object \n",
      " 9   squareFootage     392 non-null    float64\n",
      " 10  subdivision       314 non-null    object \n",
      " 11  yearBuilt         368 non-null    float64\n",
      " 12  zoning            207 non-null    object \n",
      " 13  bathrooms         372 non-null    float64\n",
      " 14  lotSize           360 non-null    float64\n",
      " 15  propertyType      413 non-null    object \n",
      " 16  ownerOccupied     320 non-null    float64\n",
      " 17  features          470 non-null    object \n",
      " 18  taxAssessment     360 non-null    object \n",
      " 19  propertyTaxes     350 non-null    object \n",
      " 20  owner             365 non-null    object \n",
      " 21  id                500 non-null    object \n",
      " 22  longitude         500 non-null    float64\n",
      " 23  latitude          500 non-null    float64\n",
      " 24  lastSaleDate      310 non-null    object \n",
      " 25  bedrooms          341 non-null    float64\n",
      " 26  lastSalePrice     261 non-null    float64\n",
      "dtypes: float64(9), int64(1), object(17)\n",
      "memory usage: 105.6+ KB\n"
     ]
    }
   ],
   "source": [
    "propertyrecords_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "70befb69-e46e-4c12-8881-582247dae26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approach of cleaning\n",
    "propertyrecords_df['features'] = propertyrecords_df['features'].apply(json.dumps)\n",
    "\n",
    "# second approach to find and replace the nulls\n",
    "propertyrecords_df.fillna({\n",
    "        'bedrooms': 0,\n",
    "        'addressLine2': 'Not available', \n",
    "        'squareFootage': 0,\n",
    "        'yearBuilt': 0,\n",
    "        'features': 'None',\n",
    "        'assessorID': 'Unknown',\n",
    "        'legalDescription': 'Not available',\n",
    "        'subdivision': 'Not available', \n",
    "         'zoning': 'Unknown', \n",
    "         'bathrooms': 0, \n",
    "         'lotSize': 0,\n",
    "         'propertyType': 'Unknown', \n",
    "         'taxAssessment': 'Not available',\n",
    "        'propertyTaxes':  'Not available', \n",
    "         'lastSalePrice': 0,\n",
    "        'lastSaleDate': 'Not available',\n",
    "        'owner': 'Unknown',\n",
    "        'ownerOccupied': 0,\n",
    "        'addressLine2': 'Unknown',\n",
    "        'county': 'Not available'}, inplace =True)\n",
    "\n",
    "# to extract the id from the address\n",
    "propertyrecords_df['id'] = propertyrecords_df['id'].apply(lambda x: id(x))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5870b930-9e9b-42b0-806b-972cb59fa271",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_dim = propertyrecords_df[['addressLine2','county','zipCode','formattedAddress','state','city']].drop_duplicates().reset_index(drop=True)\n",
    "location_dim['location_id'] = location_dim.index +1\n",
    "\n",
    "propertyrecords_df = propertyrecords_df.merge(\n",
    "    location_dim[['location_id', 'addressLine2','county','zipCode','formattedAddress','state','city']],  # Bring sales_id into propertyrecords_df\n",
    "    on=['addressLine2','county','zipCode','formattedAddress','state','city'],  # Match on shared columns\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "80f7fab6-e950-483f-953c-89dea5b60d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_dim = propertyrecords_df[['features', 'propertyType', 'zoning']].drop_duplicates().reset_index(drop=True)\n",
    "features_dim['feature_id'] = features_dim.index +1  # Ensure consistent naming\n",
    "\n",
    "# Merge features_dim into propertyrecords_df\n",
    "propertyrecords_df = propertyrecords_df.merge(\n",
    "    features_dim[['feature_id', 'features', 'propertyType', 'zoning']],  # Use 'feature_id' consistently\n",
    "    on=['features', 'propertyType', 'zoning'],  # Match on shared columns\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "51c56695-8df6-478b-a1de-6b93a51eb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_fact = propertyrecords_df[['lastSalePrice', 'lastSaleDate']].drop_duplicates().reset_index(drop=True)\n",
    "sales_fact['sales_id'] = sales_fact.index + 1 # Assign sales_id directly from the index\n",
    "\n",
    "# Map sales_id back to propertyrecords_df\n",
    "propertyrecords_df = propertyrecords_df.merge(\n",
    "    sales_fact[['sales_id', 'lastSalePrice', 'lastSaleDate']],  # Bring sales_id into propertyrecords_df\n",
    "    on=['lastSalePrice', 'lastSaleDate'],  # Match on shared columns\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "465ff28c-5b0b-408c-860c-03c8e9f2aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_columns = ['id', 'sales_id','feature_id','location_id','bedrooms', 'squareFootage','bathrooms', 'lotSize','lastSalePrice','lastSaleDate', 'longitude', 'latitude']\n",
    "fact_table = propertyrecords_df[fact_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6aa90333-656c-467b-9623-dbad54cd0039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 311 entries, 0 to 310\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   lastSalePrice  311 non-null    float64\n",
      " 1   lastSaleDate   311 non-null    object \n",
      " 2   sales_id       311 non-null    int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 7.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sales_fact.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6c2ea632-1c39-4bf0-bba6-c87a015cb14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataset as csv\n",
    "fact_table.to_csv('property_fact.csv', index=False)\n",
    "location_dim.to_csv('location_dimension.csv', index = False)\n",
    "sales_fact.to_csv('sales_facts.csv', index = False)\n",
    "features_dim.to_csv('features_dimension.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3d3c8-57cd-4243-a017-2007a9fd849c",
   "metadata": {},
   "source": [
    "# Loading dataset to Postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b03b023b-5217-4a32-99bc-c4b3483e21c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Postgresql\n",
    "\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e0fa098a-41df-48c2-8cba-3100a7d9fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "        host = 'localhost',\n",
    "        port = 5432,\n",
    "        user = 'postgres',\n",
    "        password = 'chichi',\n",
    "        database = 'Zapco_db')\n",
    "        \n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "conn = get_db_connection()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2020f686-b16e-4624-a8ab-697abaf16f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully.\n"
     ]
    }
   ],
   "source": [
    "def create_tables():\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Corrected SQL statements\n",
    "    create_table_query = '''\n",
    "        CREATE SCHEMA IF NOT EXISTS zapco_schema;\n",
    "\n",
    "        DROP TABLE IF EXISTS zapco_schema.fact_table;\n",
    "        DROP TABLE IF EXISTS zapco_schema.location_dim;\n",
    "        DROP TABLE IF EXISTS zapco_schema.sales_facts;\n",
    "        DROP TABLE IF EXISTS zapco_schema.features_dim;\n",
    "\n",
    "        CREATE TABLE zapco_schema.fact_table (\n",
    "            id NUMERIC, \n",
    "            sales_id NUMERIC,\n",
    "            feature_id NUMERIC,\n",
    "            location_id NUMERIC,\n",
    "            bedrooms FLOAT, \n",
    "            squareFootage FLOAT,\n",
    "            bathrooms FLOAT, \n",
    "            lotSize FLOAT,\n",
    "            lastSalePrice FLOAT,\n",
    "            lastSaleDate DATE, \n",
    "            longitude FLOAT, \n",
    "            latitude FLOAT\n",
    "        );\n",
    "\n",
    "        CREATE TABLE zapco_schema.location_dim (\n",
    "            addressLine2 VARCHAR(300),\n",
    "            county VARCHAR(300),\n",
    "            zipCode INTEGER,\n",
    "            formattedAddress VARCHAR(300),\n",
    "            state VARCHAR(200),\n",
    "            city VARCHAR(200),\n",
    "            location_id INTEGER\n",
    "        );\n",
    "\n",
    "        CREATE TABLE zapco_schema.features_dim (\n",
    "            features TEXT, \n",
    "            propertyType TEXT,\n",
    "            zoning  TEXT,\n",
    "            feature_id INT\n",
    "        );\n",
    "\n",
    "        CREATE TABLE zapco_schema.sales_facts (\n",
    "            lastSalePrice NUMERIC, \n",
    "            lastSaleDate DATE,\n",
    "            sales_id INT\n",
    "        );\n",
    "    '''\n",
    "    \n",
    "    # Execute query and commit changes\n",
    "    try:\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(\"Tables created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c138da90-e2c1-47d6-a80b-310057150bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(csv_path, table_name, fact_columns):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            # Replace 'Not available' or empty string with None for lastSaleDate column\n",
    "            row = [None if (cell == ' ' or cell == 'Not available') and col_name == 'lastSaleDate' else cell for cell, col_name in zip(row, fact_columns)]\n",
    "            \n",
    "            # Prepare placeholders for the insert statement\n",
    "            placeholders = ', '.join(['%s'] * len(row))\n",
    "            query = f'INSERT INTO {table_name} ({\", \".join(fact_columns)}) VALUES ({placeholders});'\n",
    "            \n",
    "            # Execute the query with the row data\n",
    "            cursor.execute(query, row)\n",
    "\n",
    "    # Commit the changes to the database\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the cursor and connection properly\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Define the columns for the fact table (assuming these match your table schema)\n",
    "fact_columns = ['id', 'sales_id', 'feature_id', 'location_id', 'bedrooms', 'squareFootage', 'bathrooms', 'lotSize', 'lastSalePrice', 'lastSaleDate', 'longitude', 'latitude']\n",
    "\n",
    "# Load data for the fact table\n",
    "fact_csv_path = 'property_fact.csv'\n",
    "load_data(fact_csv_path, 'zapco_schema.fact_table', fact_columns)\n",
    "\n",
    "# Load data for the features table\n",
    "features_csv_path = 'features_dimension.csv'\n",
    "load_data(features_csv_path, 'zapco_schema.features_dim', ['features', 'propertyType', 'zoning', 'feature_id'])\n",
    "\n",
    "# Load data for the location table\n",
    "location_csv_path = 'location_dimension.csv'\n",
    "load_data(location_csv_path, 'zapco_schema.location_dim', ['addressLine2', 'county', 'zipCode', 'formattedAddress', 'state', 'city', 'location_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "66479581-f333-4c47-a627-e17c9cc44974",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_csv_path = 'sales_facts.csv'\n",
    "load_data(sales_csv_path, 'zapco_schema.sales_facts',['lastSalePrice','lastSaleDate','sales_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5e4f7-3397-48d2-a8f1-6b84e7cc33a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
